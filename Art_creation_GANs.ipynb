{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sFHwkJjGXyhY"
   },
   "outputs": [],
   "source": [
    "!pip install tensorflow\n",
    "!pip install tensorflow_hub\n",
    "!pip install pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "nLogolFZP919"
   },
   "outputs": [],
   "source": [
    "# importing Libraries\n",
    "import zipfile\n",
    "import io\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from PIL import Image\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d7XeYKtCvSC9"
   },
   "outputs": [],
   "source": [
    "# Generator model\n",
    "def make_generator_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Dense(7*7*256, use_bias=False, input_shape=(100,)))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Reshape((7, 7, 256)))\n",
    "    assert model.output_shape == (None, 7, 7, 256)  # Note: None is the batch size\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False))\n",
    "    assert model.output_shape == (None, 7, 7, 128)\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
    "    assert model.output_shape == (None, 14, 14, 64)\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))\n",
    "    assert model.output_shape == (None, 28, 28, 1)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w33v0g20vrAN"
   },
   "outputs": [],
   "source": [
    "# dicriminator model\n",
    "def make_discriminator_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same',\n",
    "                                     input_shape=[28, 28, 1]))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(1))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b9Qhq9hzvjge"
   },
   "outputs": [],
   "source": [
    "# Function to preprocess images\n",
    "def preprocess_images(images, target_size=(64, 64)):\n",
    "    processed_images = []\n",
    "\n",
    "    # Ensure all images have the same shape\n",
    "    max_height = max(image.shape[0] for image in images)\n",
    "    max_width = max(image.shape[1] for image in images)\n",
    "\n",
    "    for image in images:\n",
    "        # Check if the image has the correct number of dimensions\n",
    "        if len(image.shape) == 3:  # RGB image\n",
    "            channels = image.shape[2]\n",
    "            if channels != 3:\n",
    "                raise ValueError(\"RGB images must have 3 channels.\")\n",
    "            processed_images.append(image)\n",
    "        elif len(image.shape) == 2:  # Grayscale image\n",
    "            processed_image = np.expand_dims(image, axis=-1)\n",
    "            processed_images.append(processed_image)\n",
    "        else:\n",
    "            raise ValueError(\"Invalid image shape.\")\n",
    "\n",
    "    # Resize or pad images to have the same shape\n",
    "    resized_images = []\n",
    "    for i, image in enumerate(images):\n",
    "        print(f\"Processing image {i + 1}/{len(images)} with shape {image.shape}\")\n",
    "        if image.shape[0] != max_height or image.shape[1] != max_width:\n",
    "            # Resize the image to the target size\n",
    "            resized_image = tf.image.resize_with_pad(image, target_size[0], target_size[1])\n",
    "            processed_images.append(resized_image.numpy())\n",
    "        else:\n",
    "            resized_images.append(image)\n",
    "\n",
    "    return np.array(resized_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JmPdCDVTQlEC"
   },
   "outputs": [],
   "source": [
    "# Open the ZIP file in read mode\n",
    "with zipfile.ZipFile('/content/drive/MyDrive/art_dataset.zip', 'r') as zip_file:\n",
    "    image_files = zip_file.namelist()\n",
    "    images = []\n",
    "\n",
    "    # Read image data from each file in the ZIP file\n",
    "    for file_name in image_files:\n",
    "        with zip_file.open(file_name) as image_file:\n",
    "            # Read image data from the file-like object\n",
    "            image_data = io.BytesIO(image_file.read())\n",
    "            # Open the image using PIL (Python Imaging Library)\n",
    "            image = Image.open(image_data)\n",
    "            # Convert the image to a numpy array\n",
    "            image_array = np.array(image)\n",
    "            images.append(image_array)\n",
    "\n",
    "print(images[0].shape)\n",
    "print(\"Number of images:\", len(images))\n",
    "print(\"Shape of first image:\", images[2000].shape)\n",
    "\n",
    "# Preprocess images\n",
    "preprocessed_images = preprocess_images(images)\n",
    "\n",
    "# Instantiate the generator and discriminator models\n",
    "generator = make_generator_model()\n",
    "discriminator = make_discriminator_model()\n",
    "\n",
    "# Print the summary of the models\n",
    "generator.summary()\n",
    "discriminator.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bzu0TVktwc5D"
   },
   "outputs": [],
   "source": [
    "# Define the GAN model\n",
    "def build_gan(generator, discriminator):\n",
    "    discriminator.trainable = False\n",
    "    model = Sequential([generator, discriminator])\n",
    "    model.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.0002, beta_1=0.5))\n",
    "    return model\n",
    "\n",
    "# Training function\n",
    "def train_gan(gan, generator, discriminator, dataset, latent_dim, epochs, batch_size):\n",
    "    for epoch in range(epochs):\n",
    "        for batch in dataset:\n",
    "            # Generate fake images\n",
    "            noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
    "            fake_images = generator.predict(noise)\n",
    "\n",
    "            # Combine real and fake images\n",
    "            real_images = batch\n",
    "            images = np.concatenate([real_images, fake_images])\n",
    "\n",
    "            # Labels for real and fake images\n",
    "            real_labels = np.ones((batch_size, 1))\n",
    "            fake_labels = np.zeros((batch_size, 1))\n",
    "            labels = np.concatenate([real_labels, fake_labels])\n",
    "\n",
    "            # Train discriminator\n",
    "            d_loss = discriminator.train_on_batch(images, labels)\n",
    "\n",
    "            # Train generator\n",
    "            noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
    "            g_loss = gan.train_on_batch(noise, real_labels)\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}, Discriminator Loss: {d_loss[0]}, Generator Loss: {g_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0xk3S5b7wlBf"
   },
   "outputs": [],
   "source": [
    "# Save generated images function\n",
    "def save_generated_images(generator, epoch, latent_dim, save_path, num_samples=25):\n",
    "    noise = np.random.normal(0, 1, (num_samples, latent_dim))\n",
    "    generated_images = generator.predict(noise)\n",
    "\n",
    "    # Rescale images to range [0, 255]\n",
    "    generated_images = 127.5 * generated_images + 127.5\n",
    "\n",
    "    # Save generated images as a grid\n",
    "    rows = int(np.sqrt(num_samples))\n",
    "    cols = num_samples // rows\n",
    "    grid = np.zeros((rows * generated_images.shape[1], cols * generated_images.shape[2], 3), dtype=np.uint8)\n",
    "    for i in range(rows):\n",
    "        for j in range(cols):\n",
    "            image = generated_images[i * cols + j]\n",
    "            grid[i * generated_images.shape[1]:(i + 1) * generated_images.shape[1],\n",
    "                 j * generated_images.shape[2]:(j + 1) * generated_images.shape[2]] = image.astype(np.uint8)\n",
    "\n",
    "    # Save grid of images\n",
    "    filename = f\"generated_images_epoch_{epoch}.png\"\n",
    "    tf.keras.preprocessing.image.save_img(save_path + filename, grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UU0DoblIwnJd"
   },
   "outputs": [],
   "source": [
    "#main function\n",
    "def main():\n",
    "    # Set random seed for reproducibility\n",
    "    np.random.seed(42)\n",
    "    tf.random.set_seed(42)\n",
    "\n",
    "    # Define parameters\n",
    "    latent_dim = 100\n",
    "    image_shape = (28, 28, 1)\n",
    "    epochs = 8000\n",
    "    batch_size = 128\n",
    "    save_interval = 10\n",
    "    save_path = \"generated_images/\"\n",
    "\n",
    "    # Build and compile models\n",
    "    generator = make_generator_modelnerator(latent_dim, image_shape)\n",
    "    discriminator = make_discriminator_modelr(image_shape)\n",
    "    gan = build_gan(generator, discriminator)\n",
    "\n",
    "\n",
    "    # Train GAN\n",
    "    train_gan(gan, generator, discriminator, dataset, latent_dim, epochs, batch_size)\n",
    "\n",
    "    # Save generated images at specified intervals during training\n",
    "    for epoch in range(0, epochs + 1, save_interval):\n",
    "        save_generated_images(generator, epoch, latent_dim, save_path)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
